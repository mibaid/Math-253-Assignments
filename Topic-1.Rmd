# Topic 1 Exercises

---
author: Muath Ibaid
date: 02/09/2017
---

# ISLR 2.4.1: 

#### (a) A flexible statistical learning method will be better. With the large number of n, a more flexible model will be able to match the data given our small p. A more flexible model is able to reduce the "reducible" error in the model

#### (b) An inflexible method will be better because with the small number of data, a flexible model will be overfitting the data. * 

#### (c) Flexible is better. It is able to accomodate for the nonlinear nature of the data  

#### (d) Inflexible is better. This is because the Variance is irreducible error and using a flexible model we might be overfitting

----------------

# ISLR 2.4.3: 
b)  

* Squared bias: as we increase flexibility we are more likely to fit more points in the data (decreasing MSE)  

* variance: increases constantly. As we make the model more flexible, we are fitting all the data increasing the variance (we reach the point of overfitting)

* Training error: as we increase flexibility, training error decreases because we're approaching a larger number of data and getting closer to the true distribution 

* test error: as we increase flexibility, test error falls and then rises again. This is because at some point we start overfitting. 

* Irreducible (Bayes): constantly horizantal since it is irreducible and doesn't change no matter how flexible we make the model. 

---------

# ISLR 2.4.6: 

Parametric model: tries to fit the data by estimating values for the parameters (usually using maximum likelyhood estimators).  

Non-parametric: doesn't make an assumption about the shape or the distribution of the data. It only depends on the full dataset. 

Patemetric models allow us to go beyond the data and make predictive models while non-parametric ones cannot be used the same way. Additionally, parametric models are simpler to express and use with different data samples. A parametric model can also be produced by a small number of data compared to the non-parametric model which requires a large amount of data.

non-parametric models, on the other hand, are very flexible and are able to fully fit the data. There's a bigger likelyhood that the parametric model makes wrong assumptions about the data. 

-----------

# ISLR 2.4.8:

a) 

```{r}
download.file("http://www-bcf.usc.edu/~gareth/ISL/College.csv", destfile = "College.csv")
college = read.csv("/home/local/MAC/mibaid/Math-253-Assignments-1/College.csv")
```


b) 

```{r}
rownames(college) = college[,1]
#fix(college)

college = college[,-1]
#fix(college)
```



c) 

```{r}
summary(college)

pairs(college[,1:10])

plot(college$Outstate ~ college$Private)

Elite=rep("No",nrow(college))
Elite[college$Top10perc >50]="Yes"
Elite=as.factor(Elite)
college=data.frame(college ,Elite)

summary(college$Elite)

plot(college$Outstate ~ college$Elite)

par(mfrow = c(2,2))
hist(college$Apps, breaks = 100)
hist(college$Accept, breaks = 20)
hist(college$Top10perc, breaks = 3)
hist(college$Top25perc, breaks = 200)


```


-----------

# ISLR 2.4.9:

## (a)  

```{r}
auto=read.csv("/home/local/MAC/mibaid/Math-253-Assignments-1/Auto.csv",header=T,na.strings ="?")
auto = na.omit(auto)


type_sum(auto$mpg) #Quantitative
type_sum(auto$cylinders) #Quantitative
type_sum(auto$displacement)  #Quantitative 
type_sum(auto$horsepower) #Quantitative 
type_sum(auto$weight) #Quantitative 
type_sum(auto$acceleration) #Quantitative
type_sum(auto$year) #Quantitiatve 
type_sum(auto$origin) #Qualitative
type_sum(auto$name) #Qualitative

```

## (b)

```{r}
range(auto$mpg) 
range(auto$cylinders) 
range(auto$displacement)
range(as.numeric(auto$horsepower))  
range(auto$weight)  
range(auto$acceleration) 
range(auto$year)  

```

## (c) 

```{r}

#mean: 

mean(auto$mpg) 
mean(auto$cylinders) 
mean(auto$displacement)
mean(as.numeric(auto$horsepower))  
mean(auto$weight)  
mean(auto$acceleration) 
mean(auto$year)  

################------ 

#SD 
sd(auto$mpg) 
sd(auto$cylinders) 
sd(auto$displacement)
sd(as.numeric(auto$horsepower))  
sd(auto$weight)  
sd(auto$acceleration) 
sd(auto$year)  
```


## (d)

```{r}
auto=read.csv("/home/local/MAC/mibaid/Math-253-Assignments-1/Auto.csv",header=T,na.strings ="?")
auto1 = data.frame(auto[-c(10:86),], na.strings="?")
nrow(auto1)
```

```{r}

range(auto1$mpg) 
range(auto1$cylinders) 
range(auto1$displacement)
range((auto1$horsepower))  #There's a problem with this variable. as.numeric doesn't work
range(auto1$weight)  
range(auto1$acceleration) 
range(auto1$year)  



#mean: 

mean(auto$mpg) 
mean(auto$cylinders) 
mean(auto$displacement)
mean(as.numeric(auto$horsepower))  
mean(auto$weight)  
mean(auto$acceleration) 
mean(auto$year)  

################------ 

#SD 
sd(auto$mpg) 
sd(auto$cylinders) 
sd(auto$displacement)
sd(as.numeric(auto$horsepower))  
sd(auto$weight)  
sd(auto$acceleration) 
sd(auto$year)  
```


## (e) 

```{r}
plot(as.numeric(auto$mpg) ~ auto$cylinders)
#It looks like cars with more cylinders have lower milage on average

scatterplot(auto$horsepower, auto$acceleration)
#the measure of accelaration is how many seconds it takes for the car to reach from 0-100 miles. Given this definition, the graph makes since. Higher horse power -> lower accelaration time. 

plot (auto$acceleration, auto$year)
#surprisingly no clear trends here

```


## (f)

```{r}
plot(auto$mpg~ auto$cylinders)
plot(auto$mpg ~ auto$horsepower)
plot(auto$mpg, auto$weight)
plot(auto$mpg ~ auto$acceleration)
plot(auto$mpg ~ auto$year)
```

I would use cylinders, horsepower, weight because I can see a clear trend that might be significant. 
However, I don't see the same trend with acceleration and year

-------------------

# ISLR 2.4.2:
(a) Regression. Inference. N=500, p= 4

(b) Classification. Prediction. N=20, P= 14

(c) Regression. Prediction. N=52. P=3

---------------------

# ISLR 2.4.7:

(a) Euclidean distance: 

Obs1: (0,3,0) - (0,0,0) = sqrt(3^2) = 3
Obs2: (2,0,0) - (0,0,0) = sqrt(2^2) = 2
Obs3: (0,1,3) - (0,0,0) = sqrt(10) = 3.162278
Obs4: (0,1,2) - (0,0,0) = sqrt(5) = 2.236068
Obs5: (-1,0,1) - (0,0,0) = sqrt(2) = 1.414214
Obs6: (1,1,1) - (0,0,0) = sqrt(3) = 1.732051   


(b) Prediction with K=1: Green. The closest neighbor for K=1 is 1.41 which is the 5th observation and it's green

(c) Prediction with K=3: Red. This is because 2,5 and 6 are closest neighbors and two of them are red. 

(d) Small because a small K better fits a non-linear boundy. It takes less points to make it flexible.

















  

